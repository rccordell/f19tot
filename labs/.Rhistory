mutate(sentiment = positive - negative)
ggplot(books_sentiment %>% filter(title %in% angry_books$title),
aes(index, sentiment, fill = title)) +
geom_bar(stat = "identity", show.legend = FALSE) +
facet_wrap(~title, ncol = 3, scales = "free_x")
books_chapters <- books %>%
group_by(title) %>%
mutate(chapter = cumsum(str_detect(text, regex("^chapter ", ignore_case = TRUE)))) %>%
ungroup() %>%
filter(chapter > 0) %>%
group_by(title, chapter) %>%
summarise(text = paste(text, collapse=" ")) %>%
unite(book_chapter, title, chapter)
books$text[,1]
books$text[1,]
books$text
mallet.instances <- mallet.import(id.array = as.character(nrow(books)),
text.array = as.character(books$text),
stoplist.file = "data/stopwords.txt")
mallet.instances <- mallet.import(id.array = as.character(books$title),
text.array = as.character(books$text),
stoplist.file = "data/stopwords.txt")
n.topics <- 20
topic.model <- MalletLDA(num.topics=n.topics, alpha.sum = 1, beta = 0.1)
topic.model$loadDocuments(mallet.instances)
topic.model$setAlphaOptimization(20, 50)
topic.model$train(500)
topic.model$maximize(10)
rm(books_chapters)
# What are the top 10 words in topic 2?
topic.words <- mallet.topic.words(topic.model)
mallet.top.words(topic.model, word.weights = topic.words[2,], num.top.words = 10)
topic_labels <- rep("", n.topics)
for (topic in 1:n.topics) {
topic_labels[topic] <- paste(
mallet.top.words(topic.model, topic.words[topic,], num.top.words=5)$words, collapse=" "
)}
vocabulary <- topic.model$getVocabulary()
word_freqs <- mallet.word.freqs(topic.model)
wordFrame <- topic.words %>% as_data_frame()
colnames(wordFrame) <- vocabulary
rownames(wordFrame) <- topic_labels
wordFrame <- wordFrame %>% rownames_to_column("tmodel")
View(wordFrame)
gatherWords <- wordFrame %>% gather(word, count, -tmodel) %>% filter(count!=0)
word2search <- "nice"
gatherWords %>% filter(word == word2search) %>%
ggplot() +
geom_bar(stat = "identity", aes(x=reorder(tmodel, count),y=count, fill=tmodel)) +
coord_flip() +
labs(x="Topic",y="Proportion") +
ggtitle(paste("Weight of the word", word2search, "in topics")) +
theme(plot.title = element_text(family = "Trebuchet MS", color="#666666", face="bold", size=22, hjust=0.5))
word2search <- "rocket"
gatherWords %>% filter(word == word2search) %>%
ggplot() +
geom_bar(stat = "identity", aes(x=reorder(tmodel, count),y=count, fill=tmodel)) +
coord_flip() +
labs(x="Topic",y="Proportion") +
ggtitle(paste("Weight of the word", word2search, "in topics")) +
theme(plot.title = element_text(family = "Trebuchet MS", color="#666666", face="bold", size=22, hjust=0.5))
#Gets a list of the documents and topics
doc.topics <- mallet.doc.topics(topic.model, smoothed=T, normalized=T)
rownames(doc.topics) = austen_chunks$book
colnames(doc.topics) = topic_labels
rownames(doc.topics) = books$title
colnames(doc.topics) = topic_labels
topicDF <- doc.topics %>%
as_data_frame() %>%
mutate(title = rownames(doc.topics)) %>%
gather(topic, proportion, -title)
View(topicDF)
# we could also arrange our table by title
topicDF %>%
arrange(title) %>%
View()
p <- topicDF %>%
group_by(topic) %>%
mutate(id = 1:n()) %>%
ggplot() +
geom_tile(aes(x=id,y=topic,fill=proportion,text = paste("title:", title)))
ggplotly(p)
library(plotly)
ggplotly(p)
t <- ggplot(topicDF %>%
separate(title, c("title","chunk"), sep="-")) +
geom_point(aes(x=topic,y=proportion,text = paste("title:", title))) +
coord_flip() +
facet_grid(. ~ title)
ggplotly(t)
t <- ggplot(topicDF %>%
t <- ggplot(topicDF) +
geom_point(aes(x=topic,y=proportion,text = paste("title:", title))) +
coord_flip() +
facet_grid(. ~ title)
ggplotly(t)
t <- ggplot(topicDF) +
geom_point(aes(x=topic,y=proportion,text = paste("title:", title))) +
coord_flip() +
facet_grid(. ~ title)
ggplotly(t)
rm(t)
ggplotly(p)
library(data.table)
booklist <- gutenberg_works(gutenberg_bookshelf == "Science Fiction", languages = "en", only_text = TRUE)
books <- gutenberg_download(c(booklist$gutenberg_id), meta_fields = c("title","author"), strip = TRUE) %>%
group_by(title, author) %>%
summarise(text = paste(text, collapse = " ")) %>%
ungroup() %>%
select(text, title, author)
write.csv(books, file = "data/scifi.csv")
books <- fread("data/scifi.csv", stringsAsFactors=FALSE, encoding="latin1") %>%
select(text, title, author)
books <- fread("data/scifi.csv", stringsAsFactors=FALSE, encoding="Latin-1") %>%
select(text, title, author)
View(books)
books <- fread("data/scifi.csv", stringsAsFactors=FALSE, encoding="Latin-1") %>%
group_by(title, author) %>%
summarise(text = paste(text, collapse = " ")) %>%
mutate(characters = nchar(text)) %>%
arrange(desc(characters)) %>%
ungroup() %>%
slice(1:500) %>%
select(text, title, author)
write.csv(books, file = "data/scifi.csv")
books <- slice(books, 1:250)
write.csv(books, file = "data/scifi.csv")
books <- fread("data/scifi.csv", stringsAsFactors=FALSE, encoding="Latin-1") %>%
select(text, title, author)
books_words <- books %>%
unnest_tokens(word, text)
sentiments <- get_sentiments("nrc") # %>% filter(sentiment == "anger")
View(sentiments)
sentiments <- get_sentiments("nrc")  %>% filter(sentiment == "anger")
angry_books <- books_words %>%
filter(word %in% sentiments$word) %>%
count(title, author, sort=TRUE) %>%
slice(1:9)
books_sentiment <- books_words %>%
inner_join(get_sentiments("bing")) %>%
count(title, author, index = as.numeric(rownames(.)) %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
ggplot(books_sentiment %>% filter(title %in% angry_books$title),
aes(index, sentiment, fill = title)) +
geom_bar(stat = "identity", show.legend = FALSE) +
facet_wrap(~title, ncol = 3, scales = "free_x")
mallet.instances <- mallet.import(id.array = as.character(books$title),
text.array = as.character(books$text),
stoplist.file = "data/stopwords.txt")
n.topics <- 20
topic.model <- MalletLDA(num.topics=n.topics, alpha.sum = 1, beta = 0.1)
topic.model$loadDocuments(mallet.instances)
topic.model$setAlphaOptimization(20, 50)
topic.model$train(500)
topic.model$maximize(10)
# What are the top 10 words in topic 2?
topic.words <- mallet.topic.words(topic.model)
mallet.top.words(topic.model, word.weights = topic.words[2,], num.top.words = 10)
topic_labels <- rep("", n.topics)
for (topic in 1:n.topics) {
topic_labels[topic] <- paste(
mallet.top.words(topic.model, topic.words[topic,], num.top.words=5)$words, collapse=" "
)}
vocabulary <- topic.model$getVocabulary()
word_freqs <- mallet.word.freqs(topic.model)
wordFrame <- topic.words %>% as_data_frame()
colnames(wordFrame) <- vocabulary
rownames(wordFrame) <- topic_labels
wordFrame <- wordFrame %>% rownames_to_column("tmodel")
gatherWords <- wordFrame %>% gather(word, count, -tmodel) %>% filter(count!=0)
word2search <- "rocket"
gatherWords %>% filter(word == word2search) %>%
ggplot() +
geom_bar(stat = "identity", aes(x=reorder(tmodel, count),y=count, fill=tmodel)) +
coord_flip() +
labs(x="Topic",y="Proportion") +
ggtitle(paste("Weight of the word", word2search, "in topics")) +
theme(plot.title = element_text(family = "Trebuchet MS", color="#666666", face="bold", size=22, hjust=0.5))
books <- books %>% slice(1:500)
mallet.instances <- mallet.import(id.array = as.character(books$title),
text.array = as.character(books$text),
stoplist.file = "data/stopwords.txt")
n.topics <- 20
topic.model <- MalletLDA(num.topics=n.topics, alpha.sum = 1, beta = 0.1)
topic.model$loadDocuments(mallet.instances)
topic.model$setAlphaOptimization(20, 50)
topic.model$train(500)
topic.model$maximize(10)
books <- books %>% slice(1:250)
mallet.instances <- mallet.import(id.array = as.character(books$title),
text.array = as.character(books$text),
stoplist.file = "data/stopwords.txt")
n.topics <- 20
topic.model <- MalletLDA(num.topics=n.topics, alpha.sum = 1, beta = 0.1)
topic.model$loadDocuments(mallet.instances)
topic.model$setAlphaOptimization(20, 50)
topic.model$train(500)
topic.model$maximize(10)
write.csv(books, file = "data/scifi.csv")
View(gatherWords)
books <- slice(books, 1:200)
View(books)
books <- fread("data/scifi.csv", stringsAsFactors=FALSE, encoding="Latin-1") %>%
group_by(title, author) %>%
summarise(text = paste(text, collapse = " ")) %>%
mutate(characters = nchar(text)) %>%
arrange(desc(characters)) %>%
ungroup() %>%
slice(1:150) %>%
select(text, title, author)
View(books)
write.csv(books, file = "data/scifi.csv")
books <- fread("https://raw.githubusercontent.com/rccordell/s18tot/gh-pages/labs/data/scifi.csv", stringsAsFactors=FALSE, encoding="Latin-1") %>%
select(text, title, author)
library(tidytext)
library(tidyverse)
library(gutenbergr)
library(tokenizers)
library(rtweet)
library(birdnik)
vignette(tokens)
vignette(token)
twitter_token <- create_token(
app = "Rav_Bot",
consumer_key = "4bOSrI16hLUcO17CT6zjGJrMF",
consumer_secret = "M5wyn3oG4vf9ebwuET9Dtv4pPwPLKgs5ftQTpPz25Mx8OUGsI8")
woeid <- "2367105"
trend <- getTrends(woeid)[,1] %>%
as_data_frame() %>%
rename(trend = value) %>%
filter(grepl("^#", trend))
twitter_token <- create_token(
app = "Rav_Bot",
consumer_key = "4bOSrI16hLUcO17CT6zjGJrMF",
consumer_secret = "M5wyn3oG4vf9ebwuET9Dtv4pPwPLKgs5ftQTpPz25Mx8OUGsI8")
woeid <- "2367105"
trend <- get_trends(woeid)[,1] %>%
as_data_frame() %>%
rename(trend = value) %>%
filter(grepl("^#", trend))
trend <- get_trends(woeid)[,1] %>%
as_data_frame() # %>%
View(trend)
trend <- get_trends(woeid)[,1] %>%
as_data_frame() %>%
filter(grepl("^#", trend))
View(trend)
poem <- paste(c("Leave my ", poem_word("noun"), " unbroken!—quit the ", poem_word("noun"), " above my ", poem_word("noun"), "!\n", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition")," my ", poem_word("noun"), ", and ", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition"), " my ", poem_word("noun"), '!" \nQuoth the Ravbot, "Never ', trend %>% sample_n(1), "!'"), collapse = "")
my_wordnik_key <- "d69c4ab1b7ce38d81d212b4f9990b90f6a60894c3b21f2ce8"
#the line below will set the "default" part of speech for your calls to Wordnik, but you will be able to override this setting in later code.
wordnik_pos = "adjective"
#
random_word <- function(key=my_wordnik_key,
pos=wordnik_pos, min_count=100, n=1,
min_length = 5, max_length = 10){
param <- paste0("words.json/randomWords?hasDictionaryDef=true",
"&minCorpusCount=",min_count,
"&minLength=",min_length,
"&maxLength=",max_length,
"&limit=",n,
"&includePartOfSpeech=",pos)
raw = birdnik:::query(key = key,params = param)
do.call(rbind,lapply(raw,as.data.frame))
}
random_word(pos="verb",n=5, min_count=1000)
random_word(pos="interjection",n=10, min_count=100)
poem_word <- function(x) {
random_word(pos=x,n=1,min_count=1000)[,2] %>%
as.character()
}
poem_word("interjection")
poem <- paste(c("Leave my ", poem_word("noun"), " unbroken!—quit the ", poem_word("noun"), " above my ", poem_word("noun"), "!\n", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition")," my ", poem_word("noun"), ", and ", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition"), " my ", poem_word("noun"), '!" \nQuoth the Ravbot, "Never ', trend %>% sample_n(1), "!'"), collapse = "")
cat(poem)
poem <- paste(c("Leave my ", poem_word("noun"), " unbroken!—quit the ", poem_word("noun"), " above my ", poem_word("noun"), "!\n", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition")," my heart, and", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition"), " my ", poem_word("noun"), '!" \nQuoth the Ravbot, "Never ', trend %>% sample_n(1), "!'"), collapse = "")
cat(poem)
poem <- paste(c("Leave my ", poem_word("noun"), " unbroken!—quit the ", poem_word("noun"), " above my ", poem_word("noun"), "!\n", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition")," my heart, and ", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition"), " my ", poem_word("noun"), '!" \nQuoth the Ravbot, "Never ', trend %>% sample_n(1), "!'"), collapse = "")
cat(poem)
if(nchar(poem) < 280) {
post_tweet(poem)
} else {
print("The poem is too long. Please rerun the generator and try again!")
}
library(tidyverse)
library(tidytext)
library(gutenbergr)
library(stringr)
library(data.table)
library(mallet)
library(tidyverse)
library(tidytext)
library(gutenbergr)
library(stringr)
library(data.table)
library(mallet)
books <- fread("data/scifi.csv", stringsAsFactors=FALSE, encoding="Latin-1") %>%
select(text, title, author)
View(books)
books_words <- books %>%
unnest_tokens(word, text)
View(books_words)
View(books_words)
plot(1:100,(1:100)^2)
library(tidyverse)
library(tidytext)
library(twitteR)
library(birdnik)
my_wordnik_key <- "d69c4ab1b7ce38d81d212b4f9990b90f6a60894c3b21f2ce8"
#the line below will set the "default" part of speech for your calls to Wordnik, but you will be able to override this setting in later code.
wordnik_pos = "adjective"
random_word <- function(key=my_wordnik_key,
pos=wordnik_pos, min_count=100, n=1,
min_length = 5, max_length = 10){
param <- paste0("words.json/randomWords?hasDictionaryDef=true",
"&minCorpusCount=",min_count,
"&minLength=",min_length,
"&maxLength=",max_length,
"&limit=",n,
"&includePartOfSpeech=",pos)
raw = birdnik:::query(key = key,params = param)
do.call(rbind,lapply(raw,as.data.frame))
}
random_word(pos="verb",n=5, min_count=1000)
random_word(pos="interjection",n=10, min_count=100)
poem_word <- function(x) {
random_word(pos=x,n=1,min_count=1000)[,2] %>%
as.character()
}
poem_word("interjection")
raven <- "raven"
raven
raven <- "raven"
raven
Quoth the Raven “Nevermore.”"
Quoth the Raven /“Nevermore./”"
Quoth the Raven /“Nevermore./”"
Quoth the Raven \“Nevermore.\”"
\"Get thee back into the tempest and the Night\'s Plutonian shore!
raven <- "\“Be that word our sign of parting, bird or fiend!\" I shrieked, upstarting—
raven <- "\"Be that word our sign of parting, bird or fiend!\" I shrieked, upstarting—
\"Get thee back into the tempest and the Night\'s Plutonian shore!
Leave no black plume as a token of that lie thy soul hath spoken!
Leave my loneliness unbroken!—quit the bust above my door!
Take thy beak from out my heart, and take thy form from off my door!\"
Quoth the Raven \“Nevermore.\""
Quoth the Raven \"Nevermore.\""
Leave no black plume as a token of that lie thy soul hath spoken!
Quoth the Raven \"Nevermore.\""
raven <- "\"Be that word our sign of parting, bird or fiend!\" I shrieked, upstarting—\"Get thee back into the tempest and the Night\'s Plutonian shore!
Leave no black plume as a token of that lie thy soul hath spoken!
Leave my loneliness unbroken!—quit the bust above my door!
Take thy beak from out my heart, and take thy form from off my door!\"
Quoth the Raven \"Nevermore.\""
\"Get thee back into the tempest and the Night\'s Plutonian shore!
raven <- "\"Be that word our sign of parting, bird or fiend!\" I shrieked, upstarting—\n\"Get thee back into the tempest and the Night\'s Plutonian shore!
raven <- "\"Be that word our sign of parting, bird or fiend!\" I shrieked, upstarting—\n\"Get thee back into the tempest and the Night\'s Plutonian shore! \nLeave no black plume as a token of that lie thy soul hath spoken!\nLeave my loneliness unbroken!—quit the bust above my door!\nTake thy beak from out my heart, and take thy form from off my door!\"\nQuoth the Raven \"Nevermore.\""
raven <- "Be that word our sign of parting, bird or fiend! I shrieked, upstarting—Get thee back into the tempest and the Night's Plutonian shore! Leave no black plume as a token of that lie thy soul hath spoken! Leave my loneliness unbroken!—quit the bust above my door! Take thy beak from out my heart, and take thy form from off my door! Quoth the Raven 'Nevermore.'"
raven <- list("Be","that","word","our","sign","of","parting",",","bird","or","fiend")
x[1]
raven[1]
raven[10]
raven[3]
library(rtweet)
token <- create_token(
app = "Mad-Lib Poetry App",
consumer_key = "tNh5iiXV6QNtvG3JskFNi6imL",
consumer_secret = "Ez6uQirax9EOo55uvjCOfqw3p1cgQuc81IwEdh7Wo1qzEbCa5t",
acess_token = "1100069980681498626-m7pxkLwg1yyYwXSdyU4UYYmWfx4CQA",
access_secret = "ffS4HrRH5AwXoeziOyZWIuOka8ROCWPXKl2RATybGphdh")
token <- create_token(
app = "Mad-Lib Poetry App",
consumer_key = "tNh5iiXV6QNtvG3JskFNi6imL",
consumer_secret = "Ez6uQirax9EOo55uvjCOfqw3p1cgQuc81IwEdh7Wo1qzEbCa5t",
access_token = "1100069980681498626-m7pxkLwg1yyYwXSdyU4UYYmWfx4CQA",
access_secret = "ffS4HrRH5AwXoeziOyZWIuOka8ROCWPXKl2RATybGphdh")
?create_token
token <- create_token(
app = "madlib_poetrybot",
consumer_key = "tNh5iiXV6QNtvG3JskFNi6imL",
consumer_secret = "Ez6uQirax9EOo55uvjCOfqw3p1cgQuc81IwEdh7Wo1qzEbCa5t",
access_token = "1100069980681498626-m7pxkLwg1yyYwXSdyU4UYYmWfx4CQA",
access_secret = "ffS4HrRH5AwXoeziOyZWIuOka8ROCWPXKl2RATybGphdh")
install.packages("rtweet")
install.packages("rtweet")
library("rtweet", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
remove.packages("rtweet", lib="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library(tidyverse)
library(tidytext)
# library(twitteR)
library(birdnik)
library(rtweet)
my_wordnik_key <- "d69c4ab1b7ce38d81d212b4f9990b90f6a60894c3b21f2ce8"
random_word <- function(key=my_wordnik_key,
pos=wordnik_pos, min_count=100, n=1,
min_length = 5, max_length = 10){
param <- paste0("words.json/randomWords?hasDictionaryDef=true",
"&minCorpusCount=",min_count,
"&minLength=",min_length,
"&maxLength=",max_length,
"&limit=",n,
"&includePartOfSpeech=",pos)
raw = birdnik:::query(key = key,params = param)
do.call(rbind,lapply(raw,as.data.frame))
}
random_word(pos="verb",n=5, min_count=1000)
random_word(pos="interjection",n=10, min_count=100)
poem <- paste(c(poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition")," my ", poem_word("noun"), ", and ", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition"), " my ", poem_word("noun"), "! \nQuoth the Ravbot, '", poem_word("interjection"), "!'"), collapse = "")
poem_word <- function(x) {
random_word(pos=x,n=1,min_count=1000)[,2] %>%
as.character()
}
poem_word("interjection")
poem <- paste(c(poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition")," my ", poem_word("noun"), ", and ", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition"), " my ", poem_word("noun"), "! \nQuoth the Ravbot, '", poem_word("interjection"), "!'"), collapse = "")
poem <- paste(c(poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition")," my ", poem_word("noun"), ", and ", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition"), " my ", poem_word("noun"), "! \nQuoth the Ravbot, '", poem_word("interjection"), "!'"), collapse = "")
token <- create_token(
app = "madlib_poetrybot",
consumer_key = "tNh5iiXV6QNtvG3JskFNi6imL",
consumer_secret = "Ez6uQirax9EOo55uvjCOfqw3p1cgQuc81IwEdh7Wo1qzEbCa5t",
access_token = "1100069980681498626-m7pxkLwg1yyYwXSdyU4UYYmWfx4CQA",
access_secret = "ffS4HrRH5AwXoeziOyZWIuOka8ROCWPXKl2RATybGphdh")
library(rtweet)
library("rtweet", lib.loc="~/Library/R/3.3/library")
token <- create_token(
app = "madlib_poetrybot",
consumer_key = "tNh5iiXV6QNtvG3JskFNi6imL",
consumer_secret = "Ez6uQirax9EOo55uvjCOfqw3p1cgQuc81IwEdh7Wo1qzEbCa5t",
access_token = "1100069980681498626-m7pxkLwg1yyYwXSdyU4UYYmWfx4CQA",
access_secret = "ffS4HrRH5AwXoeziOyZWIuOka8ROCWPXKl2RATybGphdh")
?create_token
install.packages("rtweet")
install.packages("rtweet")
library("rtweet", lib.loc="~/Library/R/3.3/library")
library(tidyverse)
library(tidytext)
# library(twitteR)
library(birdnik)
my_wordnik_key <- "d69c4ab1b7ce38d81d212b4f9990b90f6a60894c3b21f2ce8"
random_word <- function(key=my_wordnik_key,
pos=wordnik_pos, min_count=100, n=1,
min_length = 5, max_length = 10){
param <- paste0("words.json/randomWords?hasDictionaryDef=true",
"&minCorpusCount=",min_count,
"&minLength=",min_length,
"&maxLength=",max_length,
"&limit=",n,
"&includePartOfSpeech=",pos)
raw = birdnik:::query(key = key,params = param)
do.call(rbind,lapply(raw,as.data.frame))
}
poem_word <- function(x) {
random_word(pos=x,n=1,min_count=1000)[,2] %>%
as.character()
}
poem <- paste(c(poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition")," my ", poem_word("noun"), ", and ", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition"), " my ", poem_word("noun"), "! \nQuoth the Ravbot, '", poem_word("interjection"), "!'"), collapse = "")
library(tidyverse)
library(tidytext)
# library(twitteR)
library(birdnik)
library(rtweet)
token <- create_token(
app = "madlib_poetrybot",
consumer_key = "tNh5iiXV6QNtvG3JskFNi6imL",
consumer_secret = "Ez6uQirax9EOo55uvjCOfqw3p1cgQuc81IwEdh7Wo1qzEbCa5t",
access_token = "1100069980681498626-m7pxkLwg1yyYwXSdyU4UYYmWfx4CQA",
access_secret = "ffS4HrRH5AwXoeziOyZWIuOka8ROCWPXKl2RATybGphdh")
trends <- get_trends("boston")
View(trends)
poem <- paste(c(poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition")," my ", poem_word("noun"), ", and ", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition"), " my ", poem_word("noun"), '!" \nQuoth the Ravbot, "Never ', trend %>% sample_n(1), "!'"), collapse = "")
trends <- get_trends("boston") %>%
filter(grepl("^#", trend))
View(trends)
View(trends)
trends$trend %>% sample_n(1)
trends$trend
?sample_n
typeof(trends)
sample(trends$trend, size=1)
poem <- paste(c(poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition")," my ", poem_word("noun"), ", and ", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition"), " my ", poem_word("noun"), '!" \nQuoth the Ravbot, "Never ', sample(trends$trend, size=1), "!'"), collapse = "")
cat(poem)
post_tweet(status = poem)
poem <- paste(c(poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition")," my ", poem_word("noun"), ", and ", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition"), " my ", poem_word("noun"), '!" \nQuoth the Ravbot, "Never ', sample(trends$trend, size=1), "!'"), collapse = "")
poem <- paste(c(poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition")," my ", poem_word("noun"), ", and ", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition"), " my ", poem_word("noun"), '!" \nQuoth the Ravbot, "Never ', sample(trends$trend, size=1), "!'"), collapse = "")
nchar(poem)
poem
nouns <- list("cow","anvil","flower","tuba","parsley")
sample(nouns, 1)
past_verbs <- list("extrapolated","devoured","hypothesized","exploded","cha-cha slid")
random_word(pos="interjection",n=10, min_count=100)
random_word(pos="interjection",n=10, min_count=100)
random_word(pos="interjection",n=10, min_count=100)
exclamations <- list("gadzooks!","zounds!","hogwash!","aaarrrggghhh!","achoo")
interjections <- list("gadzooks!","zounds!","hogwash!","aaarrrggghhh!","achoo")
rm(exclamations)
paste(c(sample(past_verbs,1), " the ",sample(nouns,1), ", " sample(interjections,1), collapse = ""))
paste(c(sample(past_verbs,1), " the ", sample(nouns,1), ", " sample(interjections,1)), collapse = "")
sample(past_verbs,1)
past_verbs <- list("extrapolated","devoured","hypothesized","exploded","cha-cha slide")
past_verbs <- list("extrapolated","devoured","hypothesized","exploded","cha-cha slid")
sample(nouns,1)
sample(interjections,1)
sample(interjections,1) %>% View()
library(tidyverse)
library(tidytext)
# library(twitteR)
library(birdnik)
library(rtweet)
sample(interjections,1) %>% View()
sample(interjections,1) %>% as.character()
paste(c(as.character(sample(past_verbs,1)), " the ", as.character(sample(nouns,1)), ", " as.character(sample(interjections,1))), collapse = "")
sample(interjections,1) %>% as.character()
paste(c(as.character(sample(past_verbs,1)), " the ", as.character(sample(nouns,1)), ", ", as.character(sample(interjections,1))), collapse = "")
paste(c("Quoth the Raven, ", as.character(sample(interjections,1))), collapse = "")
